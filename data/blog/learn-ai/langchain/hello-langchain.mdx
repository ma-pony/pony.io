---
title: langchain入门教程 - Hello Langchain
date: '2023-09-12'
tags: ['python', 'GPT']
draft: false
summary: langchain入门教程 第一篇 Hello Langchain
---

# Hello Langchain

## langchain简介

langchain框架帮助开发LLM相关的应用程序，例如文档机器人，对话机器人等

他将LLM开发中的各种抽象概念都实现为独立的模块化组件，同时又基于各种组件实现了一些通用的处理流程，也就做链

langchain有[Python](https://github.com/langchain-ai/langchain)和和[JavaScript](https://github.com/langchain-ai/langchainjs)两个版本，此处仅基于Python版本进行简介

## 安装

### langchain

```shell
pip install langchain
```

### openai

我们以gpt-3.5为例，首先安装openai

```shell
pip install openai
```

同时我们需要去申请一个api_key，可以在[此处](https://platform.openai.com/account/api-keys)获取，获取到api_key之后，我们将其设置到环境变量中

```shell
export OPENAI_API_KEY="..."
```

当然你可以在运行代码是直接通过参数传递密钥，但并不建议这样做，密钥泄漏的风险很大

## Coding

langchain实际最核心的模块只有三个

- LLM：语言模型
- Prompt Template：提示词模版，更方便的生成提示词
- Output Parser：输出解析器，LLM的原始响应解析并进行格式化输出

我们以openai的模型举例

```python
from langchain.llms import OpenAI

llm = OpenAI()
llm.predict("你好 ChatGPT!")

```

通常来说我们不会直接把用户的输入直接传入模型中，而是添加到一个更大的文本中，我们称这个文本为提示词模版(概念类似于HTML模版)，默认情况下，PromptTemplate使用[Python 的 str.format](https://docs.python.org/3/library/stdtypes.html#str.format) 语法进行模板化

```python
from langchain.prompts import PromptTemplate

prompt = PromptTemplate.from_template("你好 {llm}?")
prompt.format(llm="ChatGPT")
# prompt.format(llm="Llama")
# prompt.format(llm="GPT-4")
```

说完了输入，我们再了解一下输出

通常模型会根据你的输入返回一段文本，而更多的时候我们希望获得一个结构化的数据来便于后续的处理，这个时候就用到了输出解析器。

例如我们将需要将文本按逗号分隔成一个列表，我们简单自定义一个输出解析器来处理这段逻辑

```python
from langchain.schema import BaseOutputParser

class CommaSeparatedListOutputParser(BaseOutputParser):
    """Parse the output of an LLM call to a comma-separated list."""

    def parse(self, text: str):
        """Parse the output of an LLM call."""
        return text.strip().split(", ")
```

下面我们就把现在所有的代码都组合成一条链LLMChain，通过LLMChain来获取输入变量，在传递到PromptTemplate中创建出提示词，将提示词传递给LLM，最后通过输出解析器处理输出的结果。

```python

from langchain.llms import OpenAI
from langchain.chains import LLMChain
from langchain.schema import BaseOutputParser
from langchain.prompts import PromptTemplate

class CommaSeparatedListOutputParser(BaseOutputParser):
    """Parse the output of an LLM call to a comma-separated list."""

    def parse(self, text: str):
        """Parse the output of an LLM call."""
        return text.strip().split("，")

prompt = PromptTemplate.from_template("你好{llm}！请问你擅长些什么？")

chain = LLMChain(
    llm=OpenAI(),
    prompt=prompt,
    output_parser=CommaSeparatedListOutputParser()
)
chain.run("ChatGPT")
```

Cool！

至此我们已经实现了一个最简单的应用，也了解到了组件（LLM、提示、输出解析器），后续再让我们继续深入研究下这几个组件。
