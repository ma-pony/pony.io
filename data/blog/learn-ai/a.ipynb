{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "!pip install langchain openai"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b96f3c2be3f809f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！有什么我可以帮助你的吗？\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "response = chat.predict(\"你好 Langchain!\")\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T13:44:04.580825Z",
     "start_time": "2023-09-12T13:44:02.750584Z"
    }
   },
   "id": "2e405538a4f435c4"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "282abaf7671bf7a9"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\\n你好！我们很高兴你来到OpenAI！我们致力于让人工智能技术变得安全可靠，从而改善人类的生活。我们期望你能加入我们的行列，一起见证人工智能技术的发展！'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "llm.predict(\"你好 OpenAI!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T13:48:28.233298Z",
     "start_time": "2023-09-12T13:48:22.823702Z"
    }
   },
   "id": "3ffb5be39105f923"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "['我擅长交谈', '从谈论日常话题到谈论更深入的话题', '都能够很好地交流。我擅长谈判', '以及分析技巧', '可以有效地解决问题。']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\"，\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你好{llm}！请问你擅长些什么？\")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=OpenAI(),\n",
    "    prompt=prompt,\n",
    "    output_parser=CommaSeparatedListOutputParser()\n",
    ")\n",
    "chain.run(\"ChatGPT\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T14:18:30.363789Z",
     "start_time": "2023-09-12T14:18:25.757543Z"
    }
   },
   "id": "5637b93d4f33bed7"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content='又要上班了，真是充满了新的机遇和挑战啊！虽然可能会有一些疲惫，但我们可以通过努力和积极的态度充实自己，迎接新的一天！加油！', additional_kwargs={}, example=False)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.chat import SystemMessage, SystemMessagePromptTemplate, HumanMessage, HumanMessagePromptTemplate, AIMessage, AIMessagePromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"你是一个非常有用的文本助手，你可以将用户的文本重写的更加乐观积极\",\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{text}\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm(template.format_messages(text=\"又要上班了，好累啊\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T23:38:36.359220Z",
     "start_time": "2023-09-14T23:38:32.885592Z"
    }
   },
   "id": "c5a6e029a78e9fb4"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\"\"\"\\n获取指定函数的源代码\\n\\nArgs:\\n    function_name (function): 要获取源代码的函数名\\n    \\nReturns:\\n    string: 函数的源代码\\n\"\"\"\\ndef get_source_code(function_name):\\n    return inspect.getsource(function_name)'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "\n",
    "def get_source_code(function_name):\n",
    "    return inspect.getsource(function_name)\n",
    "\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "给定一个函数名和函数源代码，生成函数注释，并填充到原函数中\n",
    "函数名: {function_name}\n",
    "函数源代码:\n",
    "{source_code}\n",
    "有函数注释的函数:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class FunctionExplainerPromptTemplate(StringPromptTemplate):\n",
    "    \"\"\"A custom prompt template that takes in the function name as input, and formats the prompt template to provide the source code of the function.\"\"\"\n",
    "\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the source code of the function\n",
    "        source_code = get_source_code(kwargs[\"function_name\"])\n",
    "\n",
    "        # Generate the prompt to be sent to the language model\n",
    "        prompt = PROMPT.format(\n",
    "            function_name=kwargs[\"function_name\"].__name__, source_code=source_code\n",
    "        )\n",
    "        return prompt\n",
    "\n",
    "    def _prompt_type(self):\n",
    "        return \"function-explainer\"\n",
    "\n",
    "template = FunctionExplainerPromptTemplate(\n",
    "    input_variables=[\"function_name\"],\n",
    "    output_variables=[\"function_explanation\"],\n",
    "    prompt=PROMPT,\n",
    ")\n",
    "\n",
    "llm = OpenAI()\n",
    "llm(template.format(function_name=get_source_code))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T08:19:45.357140Z",
     "start_time": "2023-09-17T08:19:42.914170Z"
    }
   },
   "id": "8a3ba07476f5118a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (2.3.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from pydantic) (2.6.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from pydantic) (4.7.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from pydantic) (0.5.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pydantic"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T08:11:21.176357Z",
     "start_time": "2023-09-17T08:11:19.382866Z"
    }
   },
   "id": "6f6ff38e87ed5072"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (0.0.284)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from langchain) (3.8.5)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from langchain) (2.31.0)\r\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from langchain) (0.0.33)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from langchain) (2.3.0)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from langchain) (2.0.20)\r\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from langchain) (2.8.5)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from langchain) (1.25.2)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from langchain) (6.0.1)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from langchain) (8.2.3)\r\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from langchain) (0.5.14)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from langchain) (4.0.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.5.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.6.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.4)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T05:06:34.447422Z",
     "start_time": "2023-09-21T05:06:33.228558Z"
    }
   },
   "id": "638569b74edc0855"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (0.28.0)\r\n",
      "Requirement already satisfied: requests>=2.20 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from openai) (2.31.0)\r\n",
      "Requirement already satisfied: aiohttp in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from openai) (3.8.5)\r\n",
      "Requirement already satisfied: tqdm in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from openai) (4.66.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from requests>=2.20->openai) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.7.22)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from aiohttp->openai) (4.0.3)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from aiohttp->openai) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rccpony/PycharmProjects/pony.io/.venv/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T05:07:14.396235Z",
     "start_time": "2023-09-21T05:07:12.987118Z"
    }
   },
   "id": "8cf366abab6477bb"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\\n你好！很高兴认识你！'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "llm.predict(\"你好 ChatGPT!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T05:09:54.765975Z",
     "start_time": "2023-09-21T05:09:51.634129Z"
    }
   },
   "id": "bfacf873939fb340"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'你好 ChatGPT?'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你好 {llm}?\")\n",
    "prompt.format(llm=\"ChatGPT\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T05:11:28.520107Z",
     "start_time": "2023-09-21T05:11:28.510316Z"
    }
   },
   "id": "acca679767e6fa66"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    " \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    " def parse(self, text: str):\n",
    "    \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "    return text.strip().split(\", \")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T05:13:04.971299Z",
     "start_time": "2023-09-21T05:13:04.963042Z"
    }
   },
   "id": "58ae4e5ac004a2a4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['嗨！我擅长的主要是聊天机器人',\n '能够模拟人类的聊天对话',\n '并且能够根据用户的输入而改变对话语境。我还能够为用户提供实用的信息',\n '比如旅游攻略、烹饪知识等等。']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    " \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    " def parse(self, text: str):\n",
    "    \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "    return text.strip().split(\"，\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你好{llm}！请问你擅长些什么？\")\n",
    "\n",
    "chain = LLMChain(\n",
    " llm=OpenAI(),\n",
    " prompt=prompt,\n",
    " output_parser=CommaSeparatedListOutputParser()\n",
    ")\n",
    "chain.run(\"ChatGPT\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T05:13:46.811378Z",
     "start_time": "2023-09-21T05:13:42.805126Z"
    }
   },
   "id": "169303ec13eb9283"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f27d89def0a2375e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
