---
title: 什么是embedding
date: '2024-04-20'
tags: ['python', 'embedding', 'nlp', 'ai', 'openai']
draft: false
summary: 什么是embedding
---
embedding是输入数据语义的机器学习数值表示。它们将文本、图像或音频等复杂的高维数据的含义捕获为向量。使算法能够更有效地处理和分析数据。

当您浏览社交媒体时，你会感觉内容都是为你量身定做的吗？有你关心的新闻，有你喜欢的技术教程，让你笑的前仰后合的搞笑视频，可是这些社交媒体是如何推荐你喜欢的视频资讯呢，你甚至都没有告诉过他们你喜欢的类型说明。

其实很多背后都用到了embedding的技术。

深度学习模型会分析您在线交互数据的结果。你的点赞、分享、评论、搜索、你铲屎君停留的内容，甚至你跳过的内容，它还会通过算法来预测您未来可能喜欢的内容推送给你。

同样，embedding还可以用于搜索、广告推荐等其他功能，从而创建高度个性化的用户体验。

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/912cef93-e34e-4dc6-aac6-a75a9af4c21d/906d96b1-9eef-4671-be01-3ef83b93684b/Untitled.png)

它们使高维数据更易于管理。减低了存储需求，提高了计算效率，并有助于理解大量非结构化数据。

## 为什么使用embedding?

自然语言的细微差别或大型图像、声音或用户交互数据集中的隐藏含义很难用表格来表示。传统的关系数据库无法有效地查询当前使用和产生的大多数的数据类型，使得这些信息的检索非常有限。

在embedding 空间中，同义词往往出现在相似的上下文中，并最终具有相似的embedding，这个空间是一个足够聪明的系统，可以理解 `漂亮` 和 `好看` 都是在夸一个人，不需要你明确说明。

embedding的核心是语义学，它们使用的理念是 `一个词的知名度和含义取决于它周围的词` ，并将其应用到更大的范围。

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/912cef93-e34e-4dc6-aac6-a75a9af4c21d/6faa2203-34fc-4692-8489-d54c67f7b8d8/Untitled.png)

这种技术对于创建搜索系统、推荐引擎、RAG以及任何想获取更深层次内容的应用都至关重要。

## embedding是如何实现的？

embedding是通过神经网络创建的。它们将复杂的关系和语义转换到更适合机器学习和数据处理应用的密集向量中。然后，它们可以将这些向量投射到适当的高维空间，比如说向量数据库。

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/912cef93-e34e-4dc6-aac6-a75a9af4c21d/e11977c8-3895-4d66-a6ee-73874e602df9/Untitled.png)

图中的数字是由其在向量空间内的位置隐式转换出来的。存储向量后，我们可以利用它们的空间位置属性来执行最近邻搜索。根据它们在空间位置上的接近程度来检索语义相似的项目。

## 如何创建embedding向量？

embedding是将复杂的人类语言转换为计算机可以理解的格式。它使用神经网络给输入数据分配数值，让相似的数据具有相似的数值。

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/912cef93-e34e-4dc6-aac6-a75a9af4c21d/7fa25aec-4bed-483c-9cd3-0834b6cd86fd/Untitled.png)

例如，如果我想让计算机理解 `right` 这个词，我可以指定一个数字，如`1.3`。这样，当计算机看到 `1.3` 时，他就会知道这是 `right` 。

再继续，现在，我想让计算机理解`right` 这个词的上下文。我可以使用二维向量，例如 `[1.3,1.8]` ，来表示`right` ，第一个数字 `1.3` 仍然表示单词 `right` ，第二个数字`1.8` 则表示上下文。

之后，我们可以引入更多的维度来表示更多的细微差别。例如，第三个维度表示单词的形式，第四个维度可以表示单词的情感内涵（积极、中性、消极）等等。

这个概念的演变也促进了`Word2Vec`和`Glove`等embedding模型的发展。它们通过学习理解词汇的上下文语境，为每个词生成高维向量，从而捕获其更为复杂的含义和属性。

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/912cef93-e34e-4dc6-aac6-a75a9af4c21d/069faf94-126c-4c21-93c8-f2aab701451b/Untitled.png)

然而，这些模型仍然具有局限性。它们根据单词在文本中的使用情况，为每一个单词生成一个单一向量。这就意味着`right` 一词的所有细微差别都被混合到一个向量表示中。这些信息不足以完全理解上下文。

那么，我们如何帮助计算机掌握不同语境下语言的细微差别呢？换句话说，我们应该如何区分：

- “your answer is right”
- ”turn right at the corner”
- “everyone has the right to freedom of speech”

这些句子中每一个`right`的含义呢？它们实际具有不同的含义。

这就出现了一些更先进的深度模型模型`BERT`、`GPT`等，它们基于`transformer`架构，这些模型会关注整个上下文。可以理解每一个词在其周围语境中的具体用法，然后为每个词创建不同的embedding

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/912cef93-e34e-4dc6-aac6-a75a9af4c21d/d2dfe5da-e1d4-4103-bf11-9ffffbb6a3e3/Untitled.png)

但是，这种理解和解释的过程在实践中是如何运作的呢？例如这个术语：”原生态设计“。为了生成其对应的embedding，`transformer`架构可以使用以下上下文：

- “原生态设计将自然元素通入建筑规划中”
- “具有原生态设计元素的办公室员工幸福感更高”
- “植物、自然光和水景是原生态设计的关键方面”

然后它将上下文与已知的建筑和设计原则进行比较：

- “可持续设计优先考虑环境和谐”
- “符合人体工程学的空间更容易提高用户的舒适度和健康水平”

该模型就为“原生态设计”创建了embedding向量，囊括了将自然元素融入人造环境的概念。同时还提添加了一些额外的属性，来强调与其对健康、幸福和环境可持续性直接的相关性。

现在您已经熟悉了向量嵌入的核心概念，那么尝试去了解更多吧！