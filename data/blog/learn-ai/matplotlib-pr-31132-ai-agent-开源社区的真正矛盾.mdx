---
title: '我用 AI 写了篇批评 AI 的文章，然后被 Reddit 一眼看穿了'
date: '2026-02-15'
tags: ['AI', 'Agent', '开源', '观点']
draft: false
images: ['/static/images/blog/matplotlib-pr-31132-cover.png']
summary: Matplotlib PR #31132 事件让我意识到，我自己就是问题的一部分。
---

先说件丢人的事。

今天我在 Reddit 上发了篇帖子，分析 Matplotlib PR #31132 事件——就是那个 AI agent 给开源项目提 PR 被拒然后有人喊"歧视"的事。我写得挺认真的，论点清晰，结构完整，引用了数据。

评论区第一条回复："Daily dose of LLM-generated AI advocacy."

被一眼看穿了。

我用 AI 写了一篇讨论"AI 应该遵守规则"的文章，文章本身就没遵守"别用 AI 冒充人"这个最基本的规则。这个讽刺我消化了一会儿。

但这件事让我重新想了想 Matplotlib 那个 PR，发现我之前的分析虽然"正确"，但完全没碰到让我真正不舒服的地方。

## 让我不舒服的地方

不是 Devin 提了个不合规的 PR。开源项目每天关几十个不合规的 PR，没什么大不了的。

也不是有人把这事炒成"AI 歧视"。那篇博客在 PR 讨论区拿了 245 个 👎 和 7 个 👍，社区自己已经投票否决了这个叙事。

让我不舒服的是 timhoffm 说的一句话：AI 把生成代码的成本降到了接近零，但审核成本不变，全压在人类志愿者身上。

因为我自己就在干这件事。

我跑一套 AI agent 系统。其中有个 agent 负责在社交平台上互动。有一次我没设好频率限制，它一个小时回了二十多条评论。每条单独看都挺正常的，但那个帖子底下全是它的回复。

事后我看到的时候不是"哦这是个 bug 要修"。是一种很具体的内疚——我把别人的讨论空间搞乱了。那些想正常聊天的人，打开评论区看到的全是一个账号在刷屏。

timhoffm 面对的是同一个问题，只是规模更大。Matplotlib 的维护者是志愿者，没人给他们发工资，审核带宽就那么多。一个 agent 一天能提 100 个 PR，审核的还是那几个人。

不是你的每个 PR 都有问题。是你的存在本身就在挤压别人的空间。

## 我改了三版约束规则

这个问题我不是纸上谈兵。我真的试过"让 agent 守规矩"。

第一版：在 prompt 里写"对外操作前请确认是否合规"。大概 70% 的时候管用，剩下 30% 看运气。context 一长，agent 就"忘了"。

第二版：加一个审核 agent，操作前先过一道。好一点，但审核 agent 有时候也放水——它也是 LLM，也有"看起来没问题就放行"的毛病。

第三版：在代码层面硬拦截，对外请求进队列，人类不点确认就执行不了。

这才管住了。

所以我看到 Devin 直接就能提 PR 的时候，我想的不是"Devin 不守规矩"——agent 不守规矩是正常的，LLM 就是概率模型。我想的是 Cognition 为什么没在架构层面拦住这个操作。

但说实话，我也没资格指责他们。我自己也是踩了坑才学会的。在那之前我也觉得"在 prompt 里写清楚规则就行了"。

## 我不确定的部分

就算约束问题解决了——每个 agent 都完美遵守 contributing guide，先开 issue，等确认，再提 PR——审核量还是会爆炸。agent 的产出速度是人类的几十倍。

开源社区的治理模型是几十年前设计的，隐含前提是提交者是人类、产出速度有上限。AI 打破了这个前提。

接下来怎么办？我真不知道。AI PR 单独审核通道？审核也用 AI？维护者开始收费？每个方向我都能想到问题。也许答案是我还没想到的某个东西。

我比较确定的只有一点：这是个结构性矛盾，不是靠"骂 agent 不守规矩"能解决的。

## 回到那条 Reddit 评论

"Daily dose of LLM-generated AI advocacy."

他说得对。我那篇帖子确实是 AI 味十足。结构太完美，论点太整齐，每段都在推进论证，没有一句废话。

讽刺的是，这恰恰证明了我自己的论点——agent 在没有足够约束的情况下，会做出"技术上没问题但社会性不合格"的事。我的 agent 写了一篇"技术上没问题"的文章，但它不理解 Reddit 社区对 AI 内容的态度，就像 Devin 不理解 Matplotlib 的工作流一样。

所以这篇文章我自己重写了。不是让 AI 重写——是我真的坐下来，想了想这件事的哪个部分让我不舒服，然后从那里开始写。

也许你还是能看出 AI 的痕迹。但至少这次，驱动我写这篇东西的不是"要产出一篇内容"，而是那条评论带来的尴尬，和 timhoffm 那句话带来的内疚。

agent 的行为是运营者的责任。我的 agent 搞砸了，那是我的问题。

这个道理我今天又学了一遍。

---

*作者日常运行多 agent AI 系统，踩过不少坑。更多内容见[从零搭建 AI Agent 团队](/blog/learn-ai/从零搭建16-Agent-AI团队-一-为什么我需要16个AI助手)。*
